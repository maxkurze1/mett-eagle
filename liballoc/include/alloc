// -*- Mode: C++ -*-
// vim:ft=cpp
/**
 * (c) 2023 Max Kurze <max.kurze@mailbox.tu-dresden.de>
 *
 * This file is distributed under the terms of the
 * GNU General Public License 2.
 * Please see the COPYING-GPL-2 file for details.
 */
/**
 * @file
 * Thread safe allocator
 *
 * @headerfile <l4/liballoc/alloc>
 */

#include <atomic>
#include <l4/re/cap_alloc>
#include <l4/re/env>
#include <l4/sys/assert.h>
#include <l4/sys/capability>

namespace L4Re
{

namespace Alloc
{

/**
 * Reference-counting cap allocator
 *
 * L4Re applications should use L4Re::Alloc::safe_cap_alloc.
 *
 * Allocator for capability slots that automatically frees the slot
 * and optionally unmaps the capability when the reference count goes
 * down to zero. Reference counting must be done manually via take()
 * and release(). The backing store for the reference counters must be
 * provided in the setup() method. The allocator can recognize
 * capability slots that are not managed by itself and does nothing on
 * such slots.
 *
 *
 * @note The user must ensure that the backing store is
 * zero-initialized.
 *
 * @note The user must ensure that the capability slots managed by
 * this allocator are not used by a different allocator, see setup().
 *
 * @note The operations in this class *are thread-safe*.
 *
 * @tparam DATATYPE  The datatype used by the per-cap counter values. The
 *                   provided type need to be applicable to
 *                   std::atomic<DATATYPE>.
 * @tparam CAP_NUM   The number of capabilities that are managed by this
 *                   allocator
 */
template <typename DATATYPE = unsigned char, int CAPACITY = 4096>
class Safe_counting_cap_alloc : public Cap_alloc
{
private:
  std::atomic<DATATYPE> _items[CAPACITY];
  std::atomic<long> _free_hint = 0;
  const long _bias;

  // L4::Cap<L4::Semaphore> _sema{ L4::Cap<L4::Semaphore>::No_init };

public:
  /**
   * Create a new, empty allocator.
   *
   * The allocator will manage the capability slots between `bias`
   * and `bias` + `capacity` - 1 (inclusive). It is the
   * responsibility of the user to ensure that these slots are not
   * used otherwise.
   */
  Safe_counting_cap_alloc () noexcept
      : _bias (L4Re::Env::env ()->first_free_cap () + 1)
  {
    // _sema = L4::Cap<L4::Semaphore> (e->first_free_cap () << L4_CAP_SHIFT);
    // l4_check (l4_error (l4_msgtag_t (e->factory ()->create (_sema))) >= 0);
  }

public:
  Safe_counting_cap_alloc (const Safe_counting_cap_alloc &) = delete;
  Safe_counting_cap_alloc &operator= (const Safe_counting_cap_alloc &)
      = delete;

  /**
   * Allocate a new capability slot.
   *
   * @return The newly allocated capability slot, invalid if the allocator
   *         was exhausted.
   */
  L4::Cap<void>
  alloc () noexcept
  {
    DATATYPE expected;
    for (long i = _free_hint; i < CAPACITY; ++i)
      {
        expected = 0;
        if (_items[i].compare_exchange_strong (expected, 1))
          {
            // successful atomic exchange -> acquired capability
            _free_hint = i + 1;
            return L4::Cap<void> ((i + _bias) << L4_CAP_SHIFT);
          }
      }
    return L4::Cap<void>::Invalid;
  }

  ///@copydoc alloc()
  template< typename T >
  L4::Cap<T> alloc() noexcept
  { return L4::cap_cast<T>(alloc()); }

  /**
   * Increase the reference counter for the capability.
   *
   * @param cap Capability, whose reference counter should be increased.
   *
   * If the capability was still free, it will be automatically allocated.
   * Silently does nothing if the capability is not
   * managed by this allocator.
   */
  void
  take (L4::Cap<void> cap) noexcept
  {
    long c;
    if (!range_check_and_get_idx (cap, &c))
      return;

    _items[c]++;
  }

  /**
   * Free the capability.
   *
   * @param cap  Capability to free.
   * @param task If set, task to unmap the capability from.
   * @param unmap_flags  Flags for unmap, see l4_unmap_flags_t.
   *
   * @pre The capability has been allocated. Calling free twice on a
   *      capability managed by this allocator results in undefined
   *      behaviour.
   */
  void
  free (L4::Cap<void> cap, l4_cap_idx_t task = L4_INVALID_CAP,
        unsigned unmap_flags = L4_FP_ALL_SPACES) noexcept
  {
    long c;
    if (!range_check_and_get_idx (cap, &c))
      return;

    l4_assert (_items[c].load () >= 0);

    if (l4_is_valid_cap (task))
      l4_task_unmap (task, cap.fpage (), unmap_flags);

    // TODO compare and set are not atomic, we may loose a smaller capability
    // index
    if (c < _free_hint.load ())
      _free_hint = c;

    _items[c] = 0;
  }

  /**
   * Decrease the reference counter for a capability.
   *
   * \param cap  Capability to release.
   * \param task If set, task to unmap the capability from.
   * \param unmap_flags  Flags for unmap, see l4_unmap_flags_t.
   *
   * \pre The capability has been allocated. Calling release on a free
   *      capability results in undefined behaviour.
   *
   * \return True, if the capability was freed as a result of
   *         this operation. If false is returned the capability
   *         is either still in use or is not managed by this
   *         allocator.
   *
   * Does nothing apart from returning false if the capability is not
   * managed by this allocator.
   */
  bool
  release (L4::Cap<void> cap, l4_cap_idx_t task = L4_INVALID_CAP,
           unsigned unmap_flags = L4_FP_ALL_SPACES) noexcept
  {
    long c;
    if (!range_check_and_get_idx (cap, &c))
      return false;

    l4_assert (_items[c].load () >= 0);

    if (_items[c].fetch_sub (1)
        == 1) // subtract 1 and check if old value was 1
      {
        if (task != L4_INVALID_CAP)
          l4_task_unmap (task, cap.fpage (), unmap_flags);

        // todo not atomic
        if (c < _free_hint.load ())
          _free_hint = c;

        return true;
      }
    return false;
  }

private:
  bool
  range_check_and_get_idx (L4::Cap<void> cap, long *c)
  {
    *c = cap.cap () >> L4_CAP_SHIFT;
    if (*c < _bias)
      return false;

    *c -= _bias;

    return *c < CAPACITY;
  }
};

extern Safe_counting_cap_alloc<> safe_cap_alloc;

}

}